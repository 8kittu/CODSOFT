# -*- coding: utf-8 -*-
"""FACE DETECTION AND RECOGNITION.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OHSeG336mM04q4GxApx0kgoqtVMXvA0C
"""

import cv2
from google.colab.patches import cv2_imshow

# Load pre-trained Haar Cascade model
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

# Read the image
image = cv2.imread('/content/girl-1894125_640.jpg')
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Detect faces
faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

# Draw rectangles around faces
for (x, y, w, h) in faces:
    cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)

# Display the image using cv2_imshow
cv2_imshow(image)

!pip install mtcnn

from mtcnn import MTCNN
import cv2
from google.colab.patches import cv2_imshow

# Initialize MTCNN detector
detector = MTCNN()

# Read the image
image = cv2.imread('/content/girl-1894125_640.jpg')

# Detect faces
faces = detector.detect_faces(image)

# Draw rectangles around faces
for face in faces:
    x, y, width, height = face['box']
    cv2.rectangle(image, (x, y), (x+width, y+height), (255, 0, 0), 2)

# Display the image using cv2_imshow
cv2_imshow(image)

!pip install dlib
!pip install opencv-python

!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2
!wget http://dlib.net/files/dlib_face_recognition_resnet_model_v1.dat.bz2
!bzip2 -d shape_predictor_68_face_landmarks.dat.bz2
!bzip2 -d dlib_face_recognition_resnet_model_v1.dat.bz2

!pip uninstall -y dlib

!pip install dlib==19.18.0

!pip install face_recognition

import face_recognition

# Load known images
known_image1 = face_recognition.load_image_file('/content/girl.jpg')
known_image2 = face_recognition.load_image_file('/content/girlssss.jpg')

# Compute face encodings
known_face_encodings = [
    face_recognition.face_encodings(known_image1)[0],
    face_recognition.face_encodings(known_image2)[0]
]

known_face_names = [
    "Person 1",
    "Person 2"
]

import face_recognition
import cv2
from google.colab.patches import cv2_imshow

# Example of known face encodings and names
# Replace these with your actual encodings and names
known_face_encodings = [
    # Example encoding arrays
    # Replace with actual encodings
]
known_face_names = [
    # Example names
    # Replace with actual names
]

# Read the image
image = cv2.imread('/content/girl-1894125_640.jpg')

# Convert the image from BGR (OpenCV) to RGB (face_recognition)
rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Detect faces and get encodings
face_locations = face_recognition.face_locations(rgb_image)
face_encodings = face_recognition.face_encodings(rgb_image, face_locations)

# Process each face detected
for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):
    # Compare face encodings with known faces
    matches = face_recognition.compare_faces(known_face_encodings, face_encoding)
    name = "Unknown"

    # Find the best match
    if True in matches:
        first_match_index = matches.index(True)
        name = known_face_names[first_match_index]

    # Draw a rectangle around the face and label it
    cv2.rectangle(image, (left, top), (right, bottom), (255, 0, 0), 2)
    cv2.putText(image, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)

# Display the image using cv2_imshow
cv2_imshow(image)

!pip install facenet-pytorch

from google.colab import files
uploaded = files.upload()

img = Image.open('/content/girl-1894125_640 (1).jpg')

import os
for filename in uploaded.keys():
    print(filename)  # Check the name of the uploaded file

from PIL import Image
import torch
from facenet_pytorch import MTCNN, InceptionResnetV1

# Initialize MTCNN for face detection and InceptionResnetV1 for face recognition
mtcnn = MTCNN(image_size=160, margin=0, min_face_size=20, keep_all=True)
resnet = InceptionResnetV1(pretrained='vggface2').eval()

# Load and align image
img = Image.open('/content/girl-1894125_640 (1).jpg')  # Update with the correct file name

# Detect faces
boxes, probs = mtcnn.detect(img)

# Ensure there are faces detected
if boxes is not None:
    img_cropped = []
    for box in boxes:
        # Ensure the box is a valid tuple
        if isinstance(box, tuple) and len(box) == 4:
            # Crop and align faces
            img_cropped.append(mtcnn(img, box))

    # Convert cropped images to tensors and calculate embeddings
    img_embeddings = []
    for img_crop in img_cropped:
        if img_crop is not None:
            img_embeddings.append(resnet(img_crop.unsqueeze(0)).detach().cpu())

    # Example: Print embeddings for each detected face
    for i, embedding in enumerate(img_embeddings):
        print(f"Face {i+1} embedding: {embedding.numpy()}")
else:
    print("No faces detected.")

print("Boxes:", boxes)
print("Probs:", probs)